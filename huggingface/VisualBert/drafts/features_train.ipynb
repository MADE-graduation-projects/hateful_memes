{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "\n",
    "import json\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir_path):\n",
    "    res = []\n",
    "    for path in os.listdir(dir_path):\n",
    "        if os.path.isfile(os.path.join(dir_path, path)) and 'outputs' in path:\n",
    "            res.append(os.path.join(dir_path, path))\n",
    "    res = sorted(res, key=lambda x: int(x.strip('.pkl').split('_')[-1]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler, device):\n",
    "    t1 = time.time()\n",
    "    best_model_name = None\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    top_val_accuracy = 0.64 \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y) in enumerate(tqdm(train_loader)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            prediction = model(x)    \n",
    "            loss_value = loss(prediction, y.type(torch.long))\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / (i_step + 1)\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Epoch: %i; %f sec; lr: %f; Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % \n",
    "              (epoch, round((time.time() - t1) * 1000, 2), get_lr(optimizer), ave_loss, train_accuracy, val_accuracy))\n",
    "\n",
    "  \n",
    "        if val_accuracy > top_val_accuracy:\n",
    "            top_val_accuracy = val_accuracy\n",
    "            model_name = f'classifier_{epoch}_{round(val_accuracy, 3)}.ckpt'\n",
    "            best_model_name = model_name\n",
    "            torch.save(model, open(model_name, 'wb'))\n",
    "            print(\"saved\", model_name)\n",
    "\n",
    "    return loss_history, train_history, val_history, best_model_name\n",
    "        \n",
    "    \n",
    "def compute_accuracy(model, loader, device):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct_samples = 0\n",
    "    total_samples = 0 \n",
    "    for i_step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        prediction = model(x)\n",
    "        _, indices = torch.max(prediction, 1)\n",
    "        correct_samples += torch.sum(indices == y)\n",
    "        total_samples += y.shape[0]            \n",
    "\n",
    "    val_accuracy = float(correct_samples) / total_samples\n",
    "         \n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feature_files, label_file):\n",
    "        self.feature_files = feature_files\n",
    "        \n",
    "        with open(label_file, 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "            self.labels = [{'id':k, 'label':labels[k]['label'], 'text':labels[k]['text']} for i, k in enumerate(labels)]\n",
    "            \n",
    "        self.current_chunk_id = -1\n",
    "        self.chunk_size = None\n",
    "        self.id2name = []\n",
    "        self.ln = 0\n",
    "        \n",
    "        for i in range(len(self.feature_files)):\n",
    "            with open(self.feature_files[i], 'rb') as f:\n",
    "                chunk = pickle.load(f)\n",
    "                self.ln += len(chunk)\n",
    "                if self.chunk_size is None or len(chunk) > self.chunk_size:\n",
    "                    self.chunk_size = len(chunk)\n",
    "                    \n",
    "                self.id2name.extend([k for k in chunk])\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        chunk_num = index // self.chunk_size\n",
    "        if chunk_num != self.current_chunk_id:\n",
    "            with open(self.feature_files[chunk_num], 'rb') as f:\n",
    "                chunk = pickle.load(f)\n",
    "                \n",
    "                self.current_chunk = [{'id':k, 'tensor':chunk[k]} for k in chunk]\n",
    "                \n",
    "                self.current_chunk_id = chunk_num\n",
    "                print(f'chunk {self.current_chunk_id} loaded')\n",
    "        \n",
    "        id1 = self.current_chunk[index % self.chunk_size]['id']\n",
    "        id2 = self.labels[index]['id']\n",
    "        id3 = self.id2name[index]\n",
    "        \n",
    "        assert id1 == id2\n",
    "        assert id2 == id3\n",
    "        return self.current_chunk[index % self.chunk_size]['tensor'], self.labels[index]['label']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 498, 498)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_val_dataset = FeaturesDataset(get_files('d:\\\\val'), 'd:\\\\val\\\\labels_val.pkl')\n",
    "len(features_val_dataset), len(features_val_dataset.labels), len(features_val_dataset.id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 loaded\n",
      "chunk 1 loaded\n",
      "chunk 2 loaded\n",
      "chunk 3 loaded\n",
      "chunk 4 loaded\n",
      "chunk 5 loaded\n",
      "chunk 6 loaded\n",
      "chunk 7 loaded\n",
      "chunk 8 loaded\n",
      "chunk 9 loaded\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features_val_dataset)):\n",
    "    features_val_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8464, 8464, 8464)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_dataset = FeaturesDataset(get_files('d:\\\\train'), 'd:\\\\train\\\\labels_train.pkl')\n",
    "\n",
    "len(features_train_dataset), len(features_train_dataset.labels), len(features_train_dataset.id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1aaa2675aef40e182ecb4e971ca754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 loaded\n",
      "torch.Size([8, 5402394]) tensor([1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in tqdm(DataLoader(features_val_dataset, batch_size=8)):\n",
    "    print(x.shape, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = features_val_dataset[0][0].shape[0]\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=5402394, out_features=256, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8af2d0fe786412f870602ff4a56fc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 loaded\n",
      "chunk 1 loaded\n",
      "chunk 2 loaded\n",
      "chunk 3 loaded\n",
      "chunk 4 loaded\n",
      "chunk 5 loaded\n",
      "chunk 6 loaded\n",
      "chunk 7 loaded\n",
      "chunk 8 loaded\n",
      "chunk 9 loaded\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"clamp_min_cpu\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(nn_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[0;32m     22\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m loss_history, train_history, val_history, best_model_name \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_val_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 21\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     22\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss(prediction, y\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong))\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\nn\\modules\\activation.py:98\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torchvision\\lib\\site-packages\\torch\\nn\\functional.py:1440\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 1440\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1442\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"clamp_min_cpu\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "\n",
    "shape = 256\n",
    "nn_model = nn.Sequential(\n",
    "            nn.Linear(input_shape, shape, dtype=torch.half),\n",
    "            #nn.Dropout(0.66),\n",
    "            #nn.BatchNorm1d(shape, dtype=torch.half),\n",
    "            nn.ReLU(inplace=True),    \n",
    "    \n",
    "            nn.Linear(shape, shape, dtype=torch.half),\n",
    "            #nn.Dropout(0.66),\n",
    "            #nn.BatchNorm1d(shape, dtype=torch.half),\n",
    "            nn.ReLU(inplace=True),    \n",
    "    \n",
    "            nn.Linear(shape, num_classes, dtype=torch.half),\n",
    "            )\n",
    "\n",
    "nn_model = nn_model.to(device)\n",
    "print(nn_model)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "loss_history, train_history, val_history, best_model_name = train_model(\n",
    "    nn_model, \n",
    "    DataLoader(features_train_dataset, batch_size=500),\n",
    "    DataLoader(features_val_dataset, batch_size=500),\n",
    "    loss, optimizer, 5, scheduler, device)\n",
    "print('end!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))    \n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_history, label='loss')\n",
    "plt.plot(train_history, label='train accuracy')\n",
    "plt.plot(val_history, label='val accuracy')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best model:\", best_model_name)\n",
    "\n",
    "best_model = torch.load(open(best_model_name, 'rb'))\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "for i_step, (x, y) in enumerate(DataLoader(features_val_dataset, batch_size=5000)):\n",
    "    prediction = best_model(x)\n",
    "\n",
    "acc_score = accuracy_score(np.array([x.item() for x in labels_val]), torch.max(prediction, 1)[1])\n",
    "auc_score = roc_auc_score(np.array([x.item() for x in labels_val]), prediction[:,1].detach().numpy())\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(labels_val, prediction[:,1].detach().numpy(), pos_label=1)\n",
    "\n",
    "random_probs = [0 for i in range(len(labels_val))]\n",
    "p_fpr, p_tpr, _ = roc_curve(labels_val, random_probs, pos_label=1)\n",
    "auc_score = roc_auc_score(labels_val, prediction[:,1].detach().numpy())\n",
    "\n",
    "print('Accuracy: ', acc_score, '\\n', 'ROC AUC: ', auc_score, sep='')\n",
    "\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "plt.title('ROC Curve', fontsize=20)\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive rate',fontsize=18)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
