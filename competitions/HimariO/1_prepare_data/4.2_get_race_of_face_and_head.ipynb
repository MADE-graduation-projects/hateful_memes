{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source https://github.com/HimariO/FairFace/blob/master/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Два первых способа установки не родошли, только этот:\n",
    "#sudo apt-get install cmake\n",
    "#wget https://files.pythonhosted.org/packages/05/57/e8a8caa3c89a27f80bc78da39c423e2553f482a3705adc619176a3a24b36/dlib-19.17.0.tar.gz\n",
    "#tar -xvzf dlib-19.17.0.tar.gz\n",
    "#cd dlib-19.17.0/\n",
    "#sudo python3 setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import fire\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from collections import Counter\n",
    "\n",
    "import dlib\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/alex/Storage/coding/HimariO/HatefulMemesChallenge/data/hateful_memes/box_annos.json',\n",
       " '/media/alex/Storage/coding/HimariO/HatefulMemesChallenge/data/hateful_memes/img_clean',\n",
       " '/media/alex/Storage/coding/HimariO/HatefulMemesChallenge/data/hateful_memes/face_race_boxes.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_dir = '/media/alex/Storage/coding/HimariO/HatefulMemesChallenge'\n",
    "gqa_box_anno = os.path.join(repo_dir, 'data/hateful_memes/box_annos.json')\n",
    "meme_img_dir = os.path.join(repo_dir, 'data/hateful_memes/img_clean')\n",
    "face_race_boxes = os.path.join(repo_dir, 'data/hateful_memes/face_race_boxes.json')\n",
    "(gqa_box_anno, meme_img_dir, face_race_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_coverage(box_a, box_b):\n",
    "    assert (box_a[2] > 1 and box_b[2] > 1) or (box_a[2] <= 1 and box_b[2] <= 1)\n",
    "    area_a = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])\n",
    "    area_b = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])\n",
    "    \n",
    "    larger = box_a if area_a > area_b else box_b\n",
    "    small = box_b if area_a > area_b else box_a\n",
    "\n",
    "    w = small[2] - small[0]\n",
    "    h = small[3] - small[1]\n",
    "    ocr_l_to_img_r = max(min(larger[2] - small[0], w), 0)\n",
    "    ocr_r_to_img_l = max(min(small[2] - larger[0], w), 0)\n",
    "    cover_w = min(ocr_l_to_img_r, ocr_r_to_img_l)\n",
    "    \n",
    "    ocr_t_to_img_b = max(min(larger[3] - small[1], h), 0)\n",
    "    ocr_b_to_img_t = max(min(small[3] - larger[1], h), 0)\n",
    "    cover_h = min(ocr_t_to_img_b, ocr_b_to_img_t)\n",
    "    return (cover_h * cover_w) / (w * h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converage_nms(primary_set, sec_set, indies=False, drop=True, threshold=0.4):\n",
    "    keep_sec = []\n",
    "    keep = []\n",
    "    for j, s_box in enumerate(sec_set):\n",
    "        covers = [0]\n",
    "        for i, p_box in enumerate(primary_set):\n",
    "            cov = box_coverage(p_box, s_box)\n",
    "            covers.append(cov)\n",
    "        \n",
    "        if drop:\n",
    "            if max(covers) < threshold:\n",
    "                keep_sec.append(s_box)\n",
    "                keep.append(j)\n",
    "        else:\n",
    "            if max(covers) >= threshold:\n",
    "                keep_sec.append(s_box)\n",
    "                keep.append(j)\n",
    "    if indies:\n",
    "        return keep_sec, keep\n",
    "    else:\n",
    "        return keep_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_race_to_person_box(img_dir, boxes_json, face_race_json, detector='oid'):\n",
    "    assert detector in ['oid', 'gqa']\n",
    "\n",
    "    person_cls = [\n",
    "        'Woman',\n",
    "        'Person',\n",
    "        'Human body',\n",
    "        'Man',\n",
    "        'Girl',\n",
    "        'Boy',\n",
    "    ] if detector == 'oid' else [\n",
    "        ''\n",
    "    ]\n",
    "    person_cls = [c.lower() for c in person_cls]\n",
    "\n",
    "    with open(boxes_json, 'r') as f:\n",
    "        det_boxes = json.load(f)\n",
    "    with open(face_race_json, 'r') as f:\n",
    "        face_det_boxes = json.load(f)\n",
    "    \n",
    "    match_cnt = []\n",
    "    for img_boxes in tqdm(det_boxes):\n",
    "        dets = img_boxes['boxes_and_score']\n",
    "        \n",
    "        img_name = img_boxes['img_name']\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        img = dlib.load_rgb_image(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        face_dets = face_det_boxes[img_name]\n",
    "        face_box = face_dets['face_boxes']\n",
    "        face_race = face_dets['face_race']\n",
    "        face_gender = face_dets['face_gender']\n",
    "\n",
    "        zip_box_size = lambda tup: (tup[0][2] - tup[0][0]) * (tup[0][3] - tup[0][1])\n",
    "        sorted_by_area = sorted(\n",
    "            zip(face_box, face_race, face_gender),\n",
    "            key=zip_box_size,\n",
    "            reverse=True)\n",
    "        face_box = [tup[0] for tup in sorted_by_area]\n",
    "        face_race = [tup[1] for tup in sorted_by_area]\n",
    "        face_gender = [tup[2] for tup in sorted_by_area]\n",
    "        \n",
    "        pbox_idx = []\n",
    "        for i, det in enumerate(dets):\n",
    "            if det['class_name'].lower() in person_cls:\n",
    "                detector_box = [\n",
    "                    det['xmin'] * w, det['ymin'] * h,\n",
    "                    det['xmax'] * w, det['ymax'] * h\n",
    "                ]\n",
    "                _, keep_idx = converage_nms(\n",
    "                    [detector_box],\n",
    "                    face_box,\n",
    "                    indies=True,\n",
    "                    drop=False,\n",
    "                    threshold=0.8,\n",
    "                )\n",
    "\n",
    "                if keep_idx:\n",
    "                    det['race'] = face_race[keep_idx[0]]\n",
    "                    det['gender'] = face_gender[keep_idx[0]]\n",
    "                    match_cnt.append(len(keep_idx))\n",
    "                else:\n",
    "                    det['race'] = None\n",
    "                    det['gender'] = None\n",
    "            else:\n",
    "                det['race'] = None\n",
    "                det['gender'] = None\n",
    "\n",
    "    print('Match cnt freq: ', Counter(match_cnt))\n",
    "    taged_box_anno_path = boxes_json.replace('.json', '.race.json')\n",
    "    with open(taged_box_anno_path, 'w') as f:\n",
    "        json.dump(det_boxes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78afc8c591fe4466b3ee265631124878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Match cnt freq:  Counter({1: 17806, 2: 2801, 3: 434, 4: 76, 5: 29, 6: 3, 7: 2})\n"
     ]
    }
   ],
   "source": [
    "map_race_to_person_box(meme_img_dir, gqa_box_anno, face_race_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат сохраняется в face_race_boxes.race.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пример\n",
    "#{\"img_name\": \"01235.png\", \"boxes_and_score\": [\n",
    "#{\"ymin\": 0.2707633674144745, \"xmin\": 0.39449542760849, \"ymax\": 0.618645429611206, \"xmax\": 0.5975348353385925, \"score\": 0.9788097739219666, \"class_name\": \"Human face\", \"class_id\": 502, \"race\": null, \"gender\": null},\n",
    "#{\"ymin\": 0.1195806935429573, \"xmin\": 0.050002746284008026, \"ymax\": 0.9922588467597961, \"xmax\": 0.9625630378723145, \"score\": 0.9190647006034851, \"class_name\": \"Man\", \"class_id\": 308, \"race\": \"Middle Eastern\", \"gender\": \"Male\"},\n",
    "#{\"ymin\": 0.49269676208496094, \"xmin\": 0.07834305614233017, \"ymax\": 0.9805120229721069, \"xmax\": 0.9698421359062195, \"score\": 0.7085372805595398, \"class_name\": \"Clothing\", \"class_id\": 433, \"race\": null, \"gender\": null},\n",
    "#{\"ymin\": 0.45603710412979126, \"xmin\": 0.020553115755319595, \"ymax\": 0.9691803455352783, \"xmax\": 0.3579131066799164, \"score\": 0.21738770604133606, \"class_name\": \"Human arm\", \"class_id\": 503, \"race\": null, \"gender\": null}]}, "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Копия блокнота \"L1_visualization.ipynb\"",
   "provenance": [
    {
     "file_id": "1WJ6MEapVkR8EgWP5ySOqChM7WYWhMwC7",
     "timestamp": 1631962727925
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
