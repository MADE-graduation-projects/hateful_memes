{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152040,
     "status": "ok",
     "timestamp": 1665646006452,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "d2SJD3quumk4",
    "outputId": "120556b6-afee-4528-e1f2-7afe728397da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting mmf\n",
      "  Downloading mmf-1.0.0rc10-cp37-cp37m-manylinux1_x86_64.whl (404 kB)\n",
      "\u001b[K     |████████████████████████████████| 404 kB 8.9 MB/s \n",
      "\u001b[?25hCollecting demjson==2.2.4\n",
      "  Downloading demjson-2.2.4.tar.gz (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 68.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from mmf) (4.64.1)\n",
      "Collecting fasttext==0.9.1\n",
      "  Downloading fasttext-0.9.1.tar.gz (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.6 MB/s \n",
      "\u001b[?25hCollecting torchtext==0.5.0\n",
      "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 926 kB/s \n",
      "\u001b[?25hCollecting sklearn==0.0\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from mmf) (1.21.6)\n",
      "Collecting torch==1.5.0\n",
      "  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 752.0 MB 9.3 kB/s \n",
      "\u001b[?25hRequirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from mmf) (2.23.0)\n",
      "Collecting torchvision==0.6.0\n",
      "  Downloading torchvision-0.6.0-cp37-cp37m-manylinux1_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nltk==3.4.5\n",
      "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 61.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from mmf) (0.5.3)\n",
      "Collecting transformers==2.3.0\n",
      "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "\u001b[K     |████████████████████████████████| 447 kB 56.7 MB/s \n",
      "\u001b[?25hCollecting omegaconf==2.0.1rc4\n",
      "  Downloading omegaconf-2.0.1rc4-py3-none-any.whl (34 kB)\n",
      "Collecting GitPython==3.1.0\n",
      "  Downloading GitPython-3.1.0-py3-none-any.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 74.2 MB/s \n",
      "\u001b[?25hCollecting lmdb==0.98\n",
      "  Downloading lmdb-0.98.tar.gz (869 kB)\n",
      "\u001b[K     |████████████████████████████████| 869 kB 74.0 MB/s \n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf) (57.4.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->mmf) (1.15.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.1rc4->mmf) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.1rc4->mmf) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf) (2022.9.24)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->mmf) (1.0.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0->mmf) (0.16.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 58.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.0->mmf) (7.1.2)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.24.89-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 72.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->mmf) (2022.6.2)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 37.5 MB/s \n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.89\n",
      "  Downloading botocore-1.27.89-py3-none-any.whl (9.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.2 MB 52.9 MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.8 MB/s \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.89->boto3->transformers==2.3.0->mmf) (2.8.2)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 77.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0->mmf) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0->mmf) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf) (1.7.3)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'omegaconf' candidate (version 2.0.1rc4 at https://files.pythonhosted.org/packages/03/c6/dec84d1b2a3d645f03201dca03bc879b6116cb6503449a31d7ff9c1394a4/omegaconf-2.0.1rc4-py3-none-any.whl#sha256=e04462f7e3d8f51532221471b241f67e35a36a04e364c70987018faadd273cc0 (from https://pypi.org/simple/omegaconf/) (requires-python:>=3.6))\n",
      "Reason for being yanked: <none given>\u001b[0m\n",
      "Building wheels for collected packages: demjson, fasttext, lmdb, nltk, sklearn, sacremoses\n",
      "  Building wheel for demjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for demjson: filename=demjson-2.2.4-py3-none-any.whl size=73565 sha256=658f23fc45d1918184e82a9b45074cf3daf1fdb5752bad6a7a322ed17acf7a73\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/94/3d/466801f4a8db8e6fce765d7a0115dfebcc55ddf6b00cd98f59\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.1-cp37-cp37m-linux_x86_64.whl size=2527392 sha256=500e1f6bcab4af6f124ca0927579956e995b3eaffe2d843dfebf153851742ccc\n",
      "  Stored in directory: /root/.cache/pip/wheels/b2/5b/4b/9c582c778bb93aaad8fc855d5e79f49eae34f59e363a22c422\n",
      "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lmdb: filename=lmdb-0.98-cp37-cp37m-linux_x86_64.whl size=219741 sha256=7cc88859587967a322135ab28f1a248534101be7b02bb7b0e841e4c186c7a9a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/9e/24/96/783d4dddcf63e3f8cc92db8b3af3c70cf6d76398bff77f1d5e\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=63a127771ff7cccbb52bd1c963f8e053c03b9116c52c342ac3e851c9f2745367\n",
      "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=233569495f658d4722d2f4d2257de9e2f1ba98ba5d1a095c2e848f6ffc302424\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=bd59ea847db69a543023378f282850bbbbbda0d9e247ad9200dbc6bdba1aad82\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built demjson fasttext lmdb nltk sklearn sacremoses\n",
      "Installing collected packages: urllib3, jmespath, botocore, smmap, s3transfer, torch, sentencepiece, sacremoses, pybind11, gitdb, boto3, transformers, torchvision, torchtext, sklearn, omegaconf, nltk, lmdb, GitPython, fasttext, demjson, mmf\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.1+cu113\n",
      "    Uninstalling torchvision-0.13.1+cu113:\n",
      "      Successfully uninstalled torchvision-0.13.1+cu113\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.13.1\n",
      "    Uninstalling torchtext-0.13.1:\n",
      "      Successfully uninstalled torchtext-0.13.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "  Attempting uninstall: lmdb\n",
      "    Found existing installation: lmdb 0.99\n",
      "    Uninstalling lmdb-0.99:\n",
      "      Successfully uninstalled lmdb-0.99\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.5.0 which is incompatible.\n",
      "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.5.0 which is incompatible.\n",
      "fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed GitPython-3.1.0 boto3-1.24.89 botocore-1.27.89 demjson-2.2.4 fasttext-0.9.1 gitdb-4.0.9 jmespath-1.0.1 lmdb-0.98 mmf-1.0.0rc10 nltk-3.4.5 omegaconf-2.0.1rc4 pybind11-2.10.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 sklearn-0.0 smmap-5.0.0 torch-1.5.0 torchtext-0.5.0 torchvision-0.6.0 transformers-2.3.0 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --pre mmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1665646006921,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "7j6nhvz_k_0n",
    "outputId": "28436088-ba08-4134-f0ae-c5b8d886e39c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.5.0', True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from google.colab import files\n",
    "torch.__version__, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7XH7EGbpZYu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3476,
     "status": "ok",
     "timestamp": 1665646010392,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "FHFDbIoophVo",
    "outputId": "eab79a9f-4833-46e0-a434-326dc3765c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmf'...\n",
      "remote: Enumerating objects: 22650, done.\u001b[K\n",
      "remote: Counting objects: 100% (2598/2598), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1007/1007), done.\u001b[K\n",
      "remote: Total 22650 (delta 1573), reused 2218 (delta 1308), pack-reused 20052\u001b[K\n",
      "Receiving objects: 100% (22650/22650), 17.16 MiB | 24.47 MiB/s, done.\n",
      "Resolving deltas: 100% (14345/14345), done.\n",
      "mmf  sample_data\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/mmf.git\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnNz79V10P3L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 777494,
     "status": "ok",
     "timestamp": 1665646787868,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "2v8FVLRmpjPh",
    "outputId": "7793fcef-1141-4801-f329-a5285a6412d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e9c9cb77-c594-4df4-9b88-9c1065be08ed\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e9c9cb77-c594-4df4-9b88-9c1065be08ed\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving hm_convert.py to hm_convert.py\n",
      "# Copyright (c) Facebook, Inc. and its affiliates.\n",
      "\n",
      "import argparse\n",
      "import hashlib\n",
      "import os\n",
      "import subprocess\n",
      "import warnings\n",
      "import zipfile\n",
      "import shutil\n",
      "\n",
      "from mmf.utils.configuration import Configuration\n",
      "#from mmf.utils.download import copy, decompress, move\n",
      "from mmf.utils.download import decompress, move\n",
      "from mmf.utils.file_io import PathManager\n",
      "\n",
      "def copy(path1, path2):\n",
      "    \"\"\"\n",
      "    Copy the given file from path1 to path2.\n",
      "    \"\"\"\n",
      "    shutil.copy(path1, path2)\n",
      "    \n",
      "class HMConverter:\n",
      "    IMAGE_FILES = [\"img.tar.gz\", \"img\"]\n",
      "    JSONL_PHASE_ONE_FILES = [\"train.jsonl\", \"dev.jsonl\", \"test.jsonl\"]\n",
      "    JSONL_PHASE_TWO_FILES = [\n",
      "        \"train.jsonl\",\n",
      "        \"dev_seen.jsonl\",\n",
      "        \"test_seen.jsonl\",\n",
      "        \"dev_unseen.jsonl\",\n",
      "        \"test_unseen.jsonl\",\n",
      "    ]\n",
      "    POSSIBLE_CHECKSUMS = [\n",
      "        \"d8f1073f5fbf1b08a541cc2325fc8645619ab8ed768091fb1317d5c3a6653a77\",\n",
      "        \"a424c003b7d4ea3f3b089168b5f5ea73b90a3ff043df4b8ff4d7ed87c51cb572\",\n",
      "        \"6e609b8c230faff02426cf462f0c9528957b7884d68c60ebc26ff83846e5f80f\",\n",
      "        \"c1363aae9649c79ae4abfdb151b56d3d170187db77757f3daa80856558ac367c\",\n",
      "    ]\n",
      "\n",
      "    def __init__(self):\n",
      "        self.parser = self.get_parser()\n",
      "        self.args = self.parser.parse_args()\n",
      "        self.configuration = Configuration()\n",
      "\n",
      "    def assert_files(self, folder):\n",
      "        files_needed = self.JSONL_PHASE_ONE_FILES\n",
      "        phase_one = True\n",
      "        for file in files_needed:\n",
      "            try:\n",
      "                assert PathManager.exists(\n",
      "                    os.path.join(folder, \"data\", file)\n",
      "                ), f\"{file} doesn't exist in {folder}\"\n",
      "            except AssertionError:\n",
      "                phase_one = False\n",
      "\n",
      "        if not phase_one:\n",
      "            files_needed = self.JSONL_PHASE_TWO_FILES\n",
      "            for file in files_needed:\n",
      "                assert PathManager.exists(\n",
      "                    os.path.join(folder, \"data\", file)\n",
      "                ), f\"{file} doesn't exist in {folder}\"\n",
      "        else:\n",
      "            warnings.warn(\n",
      "                \"You are on Phase 1 of the Hateful Memes Challenge. \"\n",
      "                \"Please update to Phase 2\"\n",
      "            )\n",
      "\n",
      "        files_needed = self.IMAGE_FILES\n",
      "\n",
      "        exists = False\n",
      "\n",
      "        for file in files_needed:\n",
      "            exists = exists or PathManager.exists(os.path.join(folder, \"data\", file))\n",
      "\n",
      "        if not exists:\n",
      "            raise AssertionError(\"Neither img or img.tar.gz exists in current zip\")\n",
      "\n",
      "        return phase_one\n",
      "\n",
      "    def get_parser(self):\n",
      "        parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)\n",
      "\n",
      "        parser.add_argument(\n",
      "            \"--zip_file\",\n",
      "            required=True,\n",
      "            type=str,\n",
      "            help=\"Zip file downloaded from the DrivenData\",\n",
      "        )\n",
      "\n",
      "        parser.add_argument(\n",
      "            \"--password\", required=True, type=str, help=\"Password for the zip file\"\n",
      "        )\n",
      "        parser.add_argument(\n",
      "            \"--move\", required=None, type=int, help=\"Move data dir to mmf cache dir\"\n",
      "        )\n",
      "        parser.add_argument(\n",
      "            \"--mmf_data_folder\", required=None, type=str, help=\"MMF Data folder\"\n",
      "        )\n",
      "        parser.add_argument(\n",
      "            \"--bypass_checksum\",\n",
      "            required=None,\n",
      "            type=int,\n",
      "            help=\"Pass 1 if you want to skip checksum\",\n",
      "        )\n",
      "        return parser\n",
      "\n",
      "    def convert(self):\n",
      "        config = self.configuration.get_config()\n",
      "        data_dir = config.env.data_dir\n",
      "\n",
      "        if self.args.mmf_data_folder:\n",
      "            data_dir = self.args.mmf_data_folder\n",
      "\n",
      "        bypass_checksum = False\n",
      "        if self.args.bypass_checksum:\n",
      "            bypass_checksum = bool(self.args.bypass_checksum)\n",
      "\n",
      "        print(f\"Data folder is {data_dir}\")\n",
      "        print(f\"Zip path is {self.args.zip_file}\")\n",
      "\n",
      "        base_path = os.path.join(data_dir, \"datasets\", \"hateful_memes\", \"defaults\")\n",
      "\n",
      "        images_path = os.path.join(base_path, \"images\")\n",
      "        PathManager.mkdirs(images_path)\n",
      "\n",
      "        move_dir = False\n",
      "        if self.args.move:\n",
      "            move_dir = bool(self.args.move)\n",
      "\n",
      "        if not bypass_checksum:\n",
      "            self.checksum(self.args.zip_file, self.POSSIBLE_CHECKSUMS)\n",
      "\n",
      "        src = self.args.zip_file\n",
      "        dest = images_path\n",
      "        if move_dir:\n",
      "            print(f\"Moving {src}\")\n",
      "            move(src, dest)\n",
      "        else:\n",
      "            print(f\"Copying {src}\")\n",
      "            copy(src, dest)\n",
      "\n",
      "        print(f\"Unzipping {src}\")\n",
      "        self.decompress_zip(\n",
      "            dest, fname=os.path.basename(src), password=self.args.password\n",
      "        )\n",
      "\n",
      "        phase_one = self.assert_files(images_path)\n",
      "\n",
      "        annotations_path = os.path.join(base_path, \"annotations\")\n",
      "        PathManager.mkdirs(annotations_path)\n",
      "        annotations = (\n",
      "            self.JSONL_PHASE_ONE_FILES\n",
      "            if phase_one is True\n",
      "            else self.JSONL_PHASE_TWO_FILES\n",
      "        )\n",
      "\n",
      "        for annotation in annotations:\n",
      "            print(f\"Moving {annotation}\")\n",
      "            src = os.path.join(images_path, \"data\", annotation)\n",
      "            dest = os.path.join(annotations_path, annotation)\n",
      "            move(src, dest)\n",
      "\n",
      "        images = self.IMAGE_FILES\n",
      "\n",
      "        for image_file in images:\n",
      "            src = os.path.join(images_path, \"data\", image_file)\n",
      "            if PathManager.exists(src):\n",
      "                print(f\"Moving {image_file}\")\n",
      "            else:\n",
      "                continue\n",
      "            dest = os.path.join(images_path, image_file)\n",
      "            move(src, dest)\n",
      "            if src.endswith(\".tar.gz\"):\n",
      "                decompress(dest, fname=image_file, delete_original=False)\n",
      "\n",
      "    def checksum(self, file, hashes):\n",
      "        sha256_hash = hashlib.sha256()\n",
      "        destination = file\n",
      "\n",
      "        with PathManager.open(destination, \"rb\") as f:\n",
      "            print(\"Starting checksum for {}\".format(os.path.basename(file)))\n",
      "            for byte_block in iter(lambda: f.read(65536), b\"\"):\n",
      "                sha256_hash.update(byte_block)\n",
      "            print(sha256_hash.hexdigest())\n",
      "            #if sha256_hash.hexdigest() not in hashes:\n",
      "            #    # remove_dir(download_path)\n",
      "            #    raise AssertionError(\n",
      "            #        f\"Checksum of downloaded file does not match the expected \"\n",
      "            #        + \"checksum. Please try again.\"\n",
      "            #    )\n",
      "            #else:\n",
      "            #    print(\"Checksum successful\")\n",
      "\n",
      "    def decompress_zip(self, dest, fname, password=None):\n",
      "        path = os.path.join(dest, fname)\n",
      "        print(\"Extracting the zip can take time. Sit back and relax.\")\n",
      "        try:\n",
      "            # Python's zip file module is very slow with password encrypted files\n",
      "            # Try command line\n",
      "            command = [\"unzip\", \"-o\", \"-q\", \"-d\", dest]\n",
      "            if password:\n",
      "                command += [\"-P\", password]\n",
      "            command += [path]\n",
      "            subprocess.run(command, check=True)\n",
      "        except Exception:\n",
      "            obj = zipfile.ZipFile(path, \"r\")\n",
      "            if password:\n",
      "                obj.setpassword(password.encode(\"utf-8\"))\n",
      "            obj.extractall(path=dest)\n",
      "            obj.close()\n",
      "\n",
      "\n",
      "def main():\n",
      "    converter = HMConverter()\n",
      "    converter.convert()\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "#Загружаем файл hm_convert.py\n",
    "files.upload()\n",
    "\n",
    "!rm mmf/mmf_cli/hm_convert.py\n",
    "!mv hm_convert.py mmf/mmf_cli\n",
    "!cat mmf/mmf_cli/hm_convert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87jBWXrvk_xW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "executionInfo": {
     "elapsed": 10782,
     "status": "ok",
     "timestamp": 1665646798634,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "RXw1eZsgk_6W",
    "outputId": "08ba9d95-dae9-4219-d39c-7c05fcce8e0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-48bd3a26-ffdb-4baa-b9a7-04bf705fbeb6\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-48bd3a26-ffdb-4baa-b9a7-04bf705fbeb6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "kaggle.json  mmf  sample_data\n"
     ]
    }
   ],
   "source": [
    "#Загружаем файл\n",
    "files.upload()\n",
    "\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35545,
     "status": "ok",
     "timestamp": 1665646834152,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "_E7ETKtnnqeX",
    "outputId": "f5869088-0bf4-4c4b-f784-aeb919c18208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading facebook-hateful-meme-dataset.zip to /content\n",
      "100% 3.35G/3.35G [00:34<00:00, 96.2MB/s]\n",
      "100% 3.35G/3.35G [00:34<00:00, 104MB/s] \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d parthplc/facebook-hateful-meme-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKM3_5Vsn59l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инструкция\n",
    "#https://github.com/facebookresearch/mmf/tree/master/projects/hateful_memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65033,
     "status": "ok",
     "timestamp": 1665646899163,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "0892_k8tn9ml",
    "outputId": "3fe33107-8572-4193-f4d5-dbc460a6942c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder is /root/.cache/torch/mmf/data\n",
      "Zip path is facebook-hateful-meme-dataset.zip\n",
      "Starting checksum for facebook-hateful-meme-dataset.zip\n",
      "d91344a36327760580607a451bc67a2436ef38251ba5699caab9b0f2965b739f\n",
      "Copying facebook-hateful-meme-dataset.zip\n",
      "Unzipping facebook-hateful-meme-dataset.zip\n",
      "Extracting the zip can take time. Sit back and relax.\n",
      "mmf/mmf_cli/hm_convert.py:63: UserWarning: You are on Phase 1 of the Hateful Memes Challenge. Please update to Phase 2\n",
      "  \"You are on Phase 1 of the Hateful Memes Challenge. \"\n",
      "Moving train.jsonl\n",
      "Moving dev.jsonl\n",
      "Moving test.jsonl\n",
      "Moving img\n"
     ]
    }
   ],
   "source": [
    "#Распаковка архива и конвертирование в mmf формат\n",
    "!python3 mmf/mmf_cli/hm_convert.py --zip_file=facebook-hateful-meme-dataset.zip --password=0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kM9rlA9mOo4c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24624084,
     "status": "ok",
     "timestamp": 1665671523226,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "gRApUqP8oLcp",
    "outputId": "3fade310-d8ad-4b84-8364-17561e006fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_override=None, local_rank=None, opts=['config=mmf/projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'training.batch_size=32'])\n",
      "/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "Overriding option config to mmf/projects/hateful_memes/configs/visual_bert/from_coco.yaml\n",
      "Overriding option model to visual_bert\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option training.batch_size to 32\n",
      "Using seed 48053078\n",
      "Logging to: ./save/logs/train_2022-10-13T07:41:48.log\n",
      "INFO:mmf.train:Loading datasets\n",
      "Downloading features.tar.gz: 100% 8.44G/8.44G [01:55<00:00, 72.9MB/s]\n",
      "Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 1.03MB/s]\n",
      "INFO:mmf.train:CUDA Device 0 is: Tesla T4\n",
      "INFO:mmf.train:Torch version is: 1.5.0\n",
      "INFO:mmf.train:Loading checkpoint\n",
      "Downloading visual_bert.pretrained.coco_train_val.tar.gz: 100% 415M/415M [00:06<00:00, 68.0MB/s]\n",
      "INFO:mmf.train:Copying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
      "INFO:mmf.train:Copying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
      "INFO:mmf.train:Copying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
      "INFO:mmf.train:Copying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
      "INFO:mmf.train:Copying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
      "INFO:mmf.train:Pretrained model loaded\n",
      "INFO:mmf.train:===== Model =====\n",
      "INFO:mmf.train:VisualBERT(\n",
      "  (model): VisualBERTForClassification(\n",
      "    (bert): VisualBERTBase(\n",
      "      (embeddings): BertVisioLinguisticEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (token_type_embeddings_visual): Embedding(2, 768)\n",
      "        (position_embeddings_visual): Embedding(512, 768)\n",
      "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Sequential(\n",
      "      (0): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (losses): Losses()\n",
      ")\n",
      "INFO:mmf.train:Total Parameters: 112044290. Trained Parameters: 112044290\n",
      "INFO:mmf.train:Starting training...\n",
      "WARNING:py.warnings:/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 100/22000, train/total_loss: 0.6252, train/total_loss/avg: 0.6252, train/hateful_memes/cross_entropy: 0.6252, train/hateful_memes/cross_entropy/avg: 0.6252, max mem: 11406.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.59, time: 02m 49s 150ms, time_since_start: 08m 05s 603ms, eta: 10h 17m 23s 942ms\n",
      "INFO:mmf.train:progress: 200/22000, train/total_loss: 0.6252, train/total_loss/avg: 0.6453, train/hateful_memes/cross_entropy: 0.6252, train/hateful_memes/cross_entropy/avg: 0.6453, max mem: 11406.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 0.57, time: 02m 54s 238ms, time_since_start: 10m 59s 842ms, eta: 10h 33m 04s 087ms\n",
      "INFO:mmf.train:progress: 300/22000, train/total_loss: 0.6654, train/total_loss/avg: 0.6554, train/hateful_memes/cross_entropy: 0.6654, train/hateful_memes/cross_entropy/avg: 0.6554, max mem: 11406.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 0.57, time: 02m 55s 688ms, time_since_start: 13m 55s 530ms, eta: 10h 35m 24s 308ms\n",
      "INFO:mmf.train:progress: 400/22000, train/total_loss: 0.6252, train/total_loss/avg: 0.6411, train/hateful_memes/cross_entropy: 0.6252, train/hateful_memes/cross_entropy/avg: 0.6411, max mem: 11406.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 0.57, time: 02m 54s 904ms, time_since_start: 16m 50s 434ms, eta: 10h 29m 39s 312ms\n",
      "INFO:mmf.train:progress: 500/22000, train/total_loss: 0.6252, train/total_loss/avg: 0.6271, train/hateful_memes/cross_entropy: 0.6252, train/hateful_memes/cross_entropy/avg: 0.6271, max mem: 11406.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 0.57, time: 02m 54s 934ms, time_since_start: 19m 45s 369ms, eta: 10h 26m 50s 890ms\n",
      "INFO:mmf.train:progress: 600/22000, train/total_loss: 0.5982, train/total_loss/avg: 0.6019, train/hateful_memes/cross_entropy: 0.5982, train/hateful_memes/cross_entropy/avg: 0.6019, max mem: 11406.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00001, ups: 0.57, time: 02m 55s 155ms, time_since_start: 22m 40s 524ms, eta: 10h 24m 43s 345ms\n",
      "INFO:mmf.train:progress: 800/22000, train/total_loss: 0.5712, train/total_loss/avg: 0.5405, train/hateful_memes/cross_entropy: 0.5712, train/hateful_memes/cross_entropy/avg: 0.5405, max mem: 11406.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 356ms, time_since_start: 28m 30s 438ms, eta: 10h 19m 35s 685ms\n",
      "INFO:mmf.train:progress: 900/22000, train/total_loss: 0.5712, train/total_loss/avg: 0.5394, train/hateful_memes/cross_entropy: 0.5712, train/hateful_memes/cross_entropy/avg: 0.5394, max mem: 11406.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 54s 245ms, time_since_start: 31m 24s 684ms, eta: 10h 12m 45s 902ms\n",
      "INFO:mmf.train:progress: 1000/22000, train/total_loss: 0.5308, train/total_loss/avg: 0.5309, train/hateful_memes/cross_entropy: 0.5308, train/hateful_memes/cross_entropy/avg: 0.5309, max mem: 11406.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 54s 932ms, time_since_start: 34m 19s 616ms, eta: 10h 12m 15s 733ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 1000/22000, val/total_loss: 0.8693, val/hateful_memes/cross_entropy: 0.8693, val/hateful_memes/accuracy: 0.6000, val/hateful_memes/binary_f1: 0.4595, val/hateful_memes/roc_auc: 0.7073, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 12s 540ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.707280\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 1100/22000, train/total_loss: 0.5308, train/total_loss/avg: 0.4944, train/hateful_memes/cross_entropy: 0.5308, train/hateful_memes/cross_entropy/avg: 0.4944, max mem: 11430.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 949ms, time_since_start: 37m 54s 294ms, eta: 10h 12m 53s 551ms\n",
      "INFO:mmf.train:progress: 1200/22000, train/total_loss: 0.4758, train/total_loss/avg: 0.4814, train/hateful_memes/cross_entropy: 0.4758, train/hateful_memes/cross_entropy/avg: 0.4814, max mem: 11430.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 863ms, time_since_start: 40m 49s 158ms, eta: 10h 06m 11s 633ms\n",
      "INFO:mmf.train:progress: 1300/22000, train/total_loss: 0.4799, train/total_loss/avg: 0.4813, train/hateful_memes/cross_entropy: 0.4799, train/hateful_memes/cross_entropy/avg: 0.4813, max mem: 11430.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 873ms, time_since_start: 43m 44s 032ms, eta: 10h 03m 18s 853ms\n",
      "INFO:mmf.train:progress: 1400/22000, train/total_loss: 0.4758, train/total_loss/avg: 0.4703, train/hateful_memes/cross_entropy: 0.4758, train/hateful_memes/cross_entropy/avg: 0.4703, max mem: 11430.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 975ms, time_since_start: 46m 40s 007ms, eta: 10h 04m 10s 911ms\n",
      "INFO:mmf.train:progress: 1500/22000, train/total_loss: 0.4758, train/total_loss/avg: 0.4518, train/hateful_memes/cross_entropy: 0.4758, train/hateful_memes/cross_entropy/avg: 0.4518, max mem: 11430.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 54s 974ms, time_since_start: 49m 34s 982ms, eta: 09h 57m 49s 827ms\n",
      "INFO:mmf.train:progress: 1600/22000, train/total_loss: 0.4538, train/total_loss/avg: 0.4353, train/hateful_memes/cross_entropy: 0.4538, train/hateful_memes/cross_entropy/avg: 0.4353, max mem: 11430.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 304ms, time_since_start: 52m 30s 287ms, eta: 09h 56m 02s 210ms\n",
      "INFO:mmf.train:progress: 1700/22000, train/total_loss: 0.4538, train/total_loss/avg: 0.4226, train/hateful_memes/cross_entropy: 0.4538, train/hateful_memes/cross_entropy/avg: 0.4226, max mem: 11430.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 54s 637ms, time_since_start: 55m 24s 924ms, eta: 09h 50m 51s 445ms\n",
      "INFO:mmf.train:progress: 1800/22000, train/total_loss: 0.3666, train/total_loss/avg: 0.4188, train/hateful_memes/cross_entropy: 0.3666, train/hateful_memes/cross_entropy/avg: 0.4188, max mem: 11430.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 54s 764ms, time_since_start: 58m 19s 688ms, eta: 09h 48m 22s 335ms\n",
      "INFO:mmf.train:progress: 1900/22000, train/total_loss: 0.3666, train/total_loss/avg: 0.4036, train/hateful_memes/cross_entropy: 0.3666, train/hateful_memes/cross_entropy/avg: 0.4036, max mem: 11430.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 56s 004ms, time_since_start: 01h 01m 15s 693ms, eta: 09h 49m 36s 937ms\n",
      "INFO:mmf.train:progress: 2000/22000, train/total_loss: 0.3543, train/total_loss/avg: 0.3932, train/hateful_memes/cross_entropy: 0.3543, train/hateful_memes/cross_entropy/avg: 0.3932, max mem: 11430.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 357ms, time_since_start: 01h 04m 11s 051ms, eta: 09h 44m 31s 509ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 2000/22000, val/total_loss: 1.0321, val/hateful_memes/cross_entropy: 1.0321, val/hateful_memes/accuracy: 0.6440, val/hateful_memes/binary_f1: 0.5266, val/hateful_memes/roc_auc: 0.7361, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 11s 748ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 2100/22000, train/total_loss: 0.3460, train/total_loss/avg: 0.3801, train/hateful_memes/cross_entropy: 0.3460, train/hateful_memes/cross_entropy/avg: 0.3801, max mem: 11430.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 668ms, time_since_start: 01h 07m 45s 369ms, eta: 09h 42m 38s 046ms\n",
      "INFO:mmf.train:progress: 2200/22000, train/total_loss: 0.3385, train/total_loss/avg: 0.3651, train/hateful_memes/cross_entropy: 0.3385, train/hateful_memes/cross_entropy/avg: 0.3651, max mem: 11430.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 543ms, time_since_start: 01h 10m 40s 913ms, eta: 09h 39m 17s 584ms\n",
      "INFO:mmf.train:progress: 2300/22000, train/total_loss: 0.3273, train/total_loss/avg: 0.3503, train/hateful_memes/cross_entropy: 0.3273, train/hateful_memes/cross_entropy/avg: 0.3503, max mem: 11430.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 188ms, time_since_start: 01h 13m 36s 101ms, eta: 09h 35m 12s 072ms\n",
      "INFO:mmf.train:progress: 2400/22000, train/total_loss: 0.2194, train/total_loss/avg: 0.3372, train/hateful_memes/cross_entropy: 0.2194, train/hateful_memes/cross_entropy/avg: 0.3372, max mem: 11430.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 56s 098ms, time_since_start: 01h 16m 32s 200ms, eta: 09h 35m 15s 329ms\n",
      "INFO:mmf.train:progress: 2500/22000, train/total_loss: 0.1961, train/total_loss/avg: 0.3249, train/hateful_memes/cross_entropy: 0.1961, train/hateful_memes/cross_entropy/avg: 0.3249, max mem: 11430.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 54s 767ms, time_since_start: 01h 19m 26s 967ms, eta: 09h 27m 59s 645ms\n",
      "INFO:mmf.train:progress: 2600/22000, train/total_loss: 0.1932, train/total_loss/avg: 0.3174, train/hateful_memes/cross_entropy: 0.1932, train/hateful_memes/cross_entropy/avg: 0.3174, max mem: 11430.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 428ms, time_since_start: 01h 22m 22s 395ms, eta: 09h 27m 13s 051ms\n",
      "INFO:mmf.train:progress: 2700/22000, train/total_loss: 0.1913, train/total_loss/avg: 0.3127, train/hateful_memes/cross_entropy: 0.1913, train/hateful_memes/cross_entropy/avg: 0.3127, max mem: 11430.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 56s 023ms, time_since_start: 01h 25m 18s 419ms, eta: 09h 26m 12s 628ms\n",
      "INFO:mmf.train:progress: 2800/22000, train/total_loss: 0.1876, train/total_loss/avg: 0.3030, train/hateful_memes/cross_entropy: 0.1876, train/hateful_memes/cross_entropy/avg: 0.3030, max mem: 11430.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 54s 978ms, time_since_start: 01h 28m 13s 398ms, eta: 09h 19m 55s 925ms\n",
      "INFO:mmf.train:progress: 2900/22000, train/total_loss: 0.1297, train/total_loss/avg: 0.2959, train/hateful_memes/cross_entropy: 0.1297, train/hateful_memes/cross_entropy/avg: 0.2959, max mem: 11430.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 54s 854ms, time_since_start: 01h 31m 08s 253ms, eta: 09h 16m 37s 220ms\n",
      "INFO:mmf.train:progress: 3000/22000, train/total_loss: 0.1294, train/total_loss/avg: 0.2880, train/hateful_memes/cross_entropy: 0.1294, train/hateful_memes/cross_entropy/avg: 0.2880, max mem: 11430.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 887ms, time_since_start: 01h 34m 04s 140ms, eta: 09h 16m 58s 702ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 3000/22000, val/total_loss: 2.0276, val/hateful_memes/cross_entropy: 2.0276, val/hateful_memes/accuracy: 0.5880, val/hateful_memes/binary_f1: 0.3795, val/hateful_memes/roc_auc: 0.7277, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 12s 058ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 3100/22000, train/total_loss: 0.1287, train/total_loss/avg: 0.2812, train/hateful_memes/cross_entropy: 0.1287, train/hateful_memes/cross_entropy/avg: 0.2812, max mem: 11430.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 549ms, time_since_start: 01h 37m 33s 087ms, eta: 09h 12m 58s 877ms\n",
      "INFO:mmf.train:progress: 3200/22000, train/total_loss: 0.1171, train/total_loss/avg: 0.2736, train/hateful_memes/cross_entropy: 0.1171, train/hateful_memes/cross_entropy/avg: 0.2736, max mem: 11430.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 500ms, time_since_start: 01h 40m 28s 588ms, eta: 09h 09m 54s 179ms\n",
      "INFO:mmf.train:progress: 3300/22000, train/total_loss: 0.0977, train/total_loss/avg: 0.2675, train/hateful_memes/cross_entropy: 0.0977, train/hateful_memes/cross_entropy/avg: 0.2675, max mem: 11430.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 270ms, time_since_start: 01h 43m 23s 859ms, eta: 09h 06m 15s 628ms\n",
      "INFO:mmf.train:progress: 3400/22000, train/total_loss: 0.0977, train/total_loss/avg: 0.2627, train/hateful_memes/cross_entropy: 0.0977, train/hateful_memes/cross_entropy/avg: 0.2627, max mem: 11430.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 250ms, time_since_start: 01h 46m 19s 110ms, eta: 09h 03m 16s 626ms\n",
      "INFO:mmf.train:progress: 3500/22000, train/total_loss: 0.0767, train/total_loss/avg: 0.2555, train/hateful_memes/cross_entropy: 0.0767, train/hateful_memes/cross_entropy/avg: 0.2555, max mem: 11430.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 56s 251ms, time_since_start: 01h 49m 15s 361ms, eta: 09h 03m 26s 499ms\n",
      "INFO:mmf.train:progress: 3600/22000, train/total_loss: 0.0767, train/total_loss/avg: 0.2559, train/hateful_memes/cross_entropy: 0.0767, train/hateful_memes/cross_entropy/avg: 0.2559, max mem: 11430.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 166ms, time_since_start: 01h 52m 10s 528ms, eta: 08h 57m 10s 687ms\n",
      "INFO:mmf.train:progress: 3700/22000, train/total_loss: 0.0726, train/total_loss/avg: 0.2506, train/hateful_memes/cross_entropy: 0.0726, train/hateful_memes/cross_entropy/avg: 0.2506, max mem: 11430.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 199ms, time_since_start: 01h 55m 05s 727ms, eta: 08h 54m 21s 540ms\n",
      "INFO:mmf.train:progress: 3800/22000, train/total_loss: 0.0599, train/total_loss/avg: 0.2448, train/hateful_memes/cross_entropy: 0.0599, train/hateful_memes/cross_entropy/avg: 0.2448, max mem: 11430.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 549ms, time_since_start: 01h 58m 01s 277ms, eta: 08h 52m 29s 995ms\n",
      "INFO:mmf.train:progress: 3900/22000, train/total_loss: 0.0599, train/total_loss/avg: 0.2418, train/hateful_memes/cross_entropy: 0.0599, train/hateful_memes/cross_entropy/avg: 0.2418, max mem: 11430.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 55s 011ms, time_since_start: 02h 56s 288ms, eta: 08h 47m 57s 071ms\n",
      "INFO:mmf.train:progress: 4000/22000, train/total_loss: 0.0599, train/total_loss/avg: 0.2385, train/hateful_memes/cross_entropy: 0.0599, train/hateful_memes/cross_entropy/avg: 0.2385, max mem: 11430.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 0.57, time: 02m 56s 356ms, time_since_start: 02h 03m 52s 645ms, eta: 08h 49m 04s 204ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 4000/22000, val/total_loss: 1.9818, val/hateful_memes/cross_entropy: 1.9818, val/hateful_memes/accuracy: 0.6180, val/hateful_memes/binary_f1: 0.4824, val/hateful_memes/roc_auc: 0.7125, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 12s 597ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 4100/22000, train/total_loss: 0.0580, train/total_loss/avg: 0.2329, train/hateful_memes/cross_entropy: 0.0580, train/hateful_memes/cross_entropy/avg: 0.2329, max mem: 11430.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 952ms, time_since_start: 02h 07m 22s 643ms, eta: 08h 44m 55s 441ms\n",
      "INFO:mmf.train:progress: 4200/22000, train/total_loss: 0.0580, train/total_loss/avg: 0.2276, train/hateful_memes/cross_entropy: 0.0580, train/hateful_memes/cross_entropy/avg: 0.2276, max mem: 11430.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 358ms, time_since_start: 02h 10m 18s 002ms, eta: 08h 40m 13s 783ms\n",
      "INFO:mmf.train:progress: 4300/22000, train/total_loss: 0.0580, train/total_loss/avg: 0.2223, train/hateful_memes/cross_entropy: 0.0580, train/hateful_memes/cross_entropy/avg: 0.2223, max mem: 11430.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 975ms, time_since_start: 02h 13m 13s 977ms, eta: 08h 39m 07s 666ms\n",
      "INFO:mmf.train:progress: 4400/22000, train/total_loss: 0.0599, train/total_loss/avg: 0.2210, train/hateful_memes/cross_entropy: 0.0599, train/hateful_memes/cross_entropy/avg: 0.2210, max mem: 11430.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 486ms, time_since_start: 02h 16m 09s 463ms, eta: 08h 34m 45s 567ms\n",
      "INFO:mmf.train:progress: 4500/22000, train/total_loss: 0.0599, train/total_loss/avg: 0.2170, train/hateful_memes/cross_entropy: 0.0599, train/hateful_memes/cross_entropy/avg: 0.2170, max mem: 11430.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 54s 917ms, time_since_start: 02h 19m 04s 381ms, eta: 08h 30m 10s 542ms\n",
      "INFO:mmf.train:progress: 4600/22000, train/total_loss: 0.0580, train/total_loss/avg: 0.2124, train/hateful_memes/cross_entropy: 0.0580, train/hateful_memes/cross_entropy/avg: 0.2124, max mem: 11430.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 175ms, time_since_start: 02h 22m 556ms, eta: 08h 30m 54s 509ms\n",
      "INFO:mmf.train:progress: 4700/22000, train/total_loss: 0.0580, train/total_loss/avg: 0.2093, train/hateful_memes/cross_entropy: 0.0580, train/hateful_memes/cross_entropy/avg: 0.2093, max mem: 11430.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 322ms, time_since_start: 02h 24m 55s 879ms, eta: 08h 25m 30s 808ms\n",
      "INFO:mmf.train:progress: 4800/22000, train/total_loss: 0.0580, train/total_loss/avg: 0.2055, train/hateful_memes/cross_entropy: 0.0580, train/hateful_memes/cross_entropy/avg: 0.2055, max mem: 11430.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 850ms, time_since_start: 02h 27m 51s 730ms, eta: 08h 24m 06s 330ms\n",
      "INFO:mmf.train:progress: 4900/22000, train/total_loss: 0.0389, train/total_loss/avg: 0.2018, train/hateful_memes/cross_entropy: 0.0389, train/hateful_memes/cross_entropy/avg: 0.2018, max mem: 11430.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 383ms, time_since_start: 02h 30m 47s 114ms, eta: 08h 19m 50s 659ms\n",
      "INFO:mmf.train:progress: 5000/22000, train/total_loss: 0.0389, train/total_loss/avg: 0.1993, train/hateful_memes/cross_entropy: 0.0389, train/hateful_memes/cross_entropy/avg: 0.1993, max mem: 11430.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 578ms, time_since_start: 02h 33m 42s 692ms, eta: 08h 17m 28s 384ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 5000/22000, val/total_loss: 1.4557, val/hateful_memes/cross_entropy: 1.4557, val/hateful_memes/accuracy: 0.6340, val/hateful_memes/binary_f1: 0.5612, val/hateful_memes/roc_auc: 0.7049, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 11s 865ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 5100/22000, train/total_loss: 0.0384, train/total_loss/avg: 0.1955, train/hateful_memes/cross_entropy: 0.0384, train/hateful_memes/cross_entropy/avg: 0.1955, max mem: 11430.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 885ms, time_since_start: 02h 37m 12s 961ms, eta: 08h 18m 13s 733ms\n",
      "INFO:mmf.train:progress: 5200/22000, train/total_loss: 0.0319, train/total_loss/avg: 0.1919, train/hateful_memes/cross_entropy: 0.0319, train/hateful_memes/cross_entropy/avg: 0.1919, max mem: 11430.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 581ms, time_since_start: 02h 40m 08s 542ms, eta: 08h 11m 37s 622ms\n",
      "INFO:mmf.train:progress: 5300/22000, train/total_loss: 0.0272, train/total_loss/avg: 0.1884, train/hateful_memes/cross_entropy: 0.0272, train/hateful_memes/cross_entropy/avg: 0.1884, max mem: 11430.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 179ms, time_since_start: 02h 43m 03s 721ms, eta: 08h 07m 34s 901ms\n",
      "INFO:mmf.train:progress: 5400/22000, train/total_loss: 0.0230, train/total_loss/avg: 0.1849, train/hateful_memes/cross_entropy: 0.0230, train/hateful_memes/cross_entropy/avg: 0.1849, max mem: 11430.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 401ms, time_since_start: 02h 45m 59s 123ms, eta: 08h 05m 16s 718ms\n",
      "INFO:mmf.train:progress: 5500/22000, train/total_loss: 0.0230, train/total_loss/avg: 0.1816, train/hateful_memes/cross_entropy: 0.0230, train/hateful_memes/cross_entropy/avg: 0.1816, max mem: 11430.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 314ms, time_since_start: 02h 48m 54s 437ms, eta: 08h 02m 06s 855ms\n",
      "INFO:mmf.train:progress: 5600/22000, train/total_loss: 0.0230, train/total_loss/avg: 0.1790, train/hateful_memes/cross_entropy: 0.0230, train/hateful_memes/cross_entropy/avg: 0.1790, max mem: 11430.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 325ms, time_since_start: 02h 51m 50s 762ms, eta: 08h 01m 57s 322ms\n",
      "INFO:mmf.train:progress: 5700/22000, train/total_loss: 0.0112, train/total_loss/avg: 0.1760, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1760, max mem: 11430.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 54s 858ms, time_since_start: 02h 54m 45s 620ms, eta: 07h 55m 01s 859ms\n",
      "INFO:mmf.train:progress: 5800/22000, train/total_loss: 0.0112, train/total_loss/avg: 0.1737, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1737, max mem: 11430.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 212ms, time_since_start: 02h 57m 40s 833ms, eta: 07h 53m 04s 369ms\n",
      "INFO:mmf.train:progress: 5900/22000, train/total_loss: 0.0112, train/total_loss/avg: 0.1729, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1729, max mem: 11430.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 806ms, time_since_start: 03h 36s 639ms, eta: 07h 51m 44s 864ms\n",
      "INFO:mmf.train:progress: 6000/22000, train/total_loss: 0.0112, train/total_loss/avg: 0.1703, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1703, max mem: 11430.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 212ms, time_since_start: 03h 03m 31s 852ms, eta: 07h 47m 13s 975ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 6000/22000, val/total_loss: 2.3458, val/hateful_memes/cross_entropy: 2.3458, val/hateful_memes/accuracy: 0.6240, val/hateful_memes/binary_f1: 0.5300, val/hateful_memes/roc_auc: 0.7062, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 12s 018ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 6100/22000, train/total_loss: 0.0170, train/total_loss/avg: 0.1678, train/hateful_memes/cross_entropy: 0.0170, train/hateful_memes/cross_entropy/avg: 0.1678, max mem: 11430.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 544ms, time_since_start: 03h 07m 889ms, eta: 07h 45m 11s 534ms\n",
      "INFO:mmf.train:progress: 6200/22000, train/total_loss: 0.0175, train/total_loss/avg: 0.1654, train/hateful_memes/cross_entropy: 0.0175, train/hateful_memes/cross_entropy/avg: 0.1654, max mem: 11430.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 690ms, time_since_start: 03h 09m 57s 579ms, eta: 07h 45m 17s 125ms\n",
      "INFO:mmf.train:progress: 6300/22000, train/total_loss: 0.0175, train/total_loss/avg: 0.1628, train/hateful_memes/cross_entropy: 0.0175, train/hateful_memes/cross_entropy/avg: 0.1628, max mem: 11430.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 739ms, time_since_start: 03h 12m 53s 319ms, eta: 07h 39m 51s 079ms\n",
      "INFO:mmf.train:progress: 6400/22000, train/total_loss: 0.0170, train/total_loss/avg: 0.1603, train/hateful_memes/cross_entropy: 0.0170, train/hateful_memes/cross_entropy/avg: 0.1603, max mem: 11430.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 332ms, time_since_start: 03h 15m 49s 651ms, eta: 07h 38m 27s 877ms\n",
      "INFO:mmf.train:progress: 6500/22000, train/total_loss: 0.0123, train/total_loss/avg: 0.1580, train/hateful_memes/cross_entropy: 0.0123, train/hateful_memes/cross_entropy/avg: 0.1580, max mem: 11430.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 571ms, time_since_start: 03h 18m 45s 223ms, eta: 07h 33m 33s 637ms\n",
      "INFO:mmf.train:progress: 6600/22000, train/total_loss: 0.0123, train/total_loss/avg: 0.1556, train/hateful_memes/cross_entropy: 0.0123, train/hateful_memes/cross_entropy/avg: 0.1556, max mem: 11430.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 676ms, time_since_start: 03h 21m 40s 900ms, eta: 07h 30m 54s 135ms\n",
      "INFO:mmf.train:progress: 6700/22000, train/total_loss: 0.0112, train/total_loss/avg: 0.1533, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1533, max mem: 11430.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 234ms, time_since_start: 03h 24m 37s 134ms, eta: 07h 29m 23s 861ms\n",
      "INFO:mmf.train:progress: 6800/22000, train/total_loss: 0.0068, train/total_loss/avg: 0.1511, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.1511, max mem: 11430.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 694ms, time_since_start: 03h 27m 32s 829ms, eta: 07h 25m 05s 588ms\n",
      "INFO:mmf.train:progress: 6900/22000, train/total_loss: 0.0051, train/total_loss/avg: 0.1489, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1489, max mem: 11430.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 316ms, time_since_start: 03h 30m 28s 146ms, eta: 07h 21m 12s 851ms\n",
      "INFO:mmf.train:progress: 7000/22000, train/total_loss: 0.0051, train/total_loss/avg: 0.1475, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1475, max mem: 11430.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 158ms, time_since_start: 03h 33m 24s 304ms, eta: 07h 20m 23s 719ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 7000/22000, val/total_loss: 1.8604, val/hateful_memes/cross_entropy: 1.8604, val/hateful_memes/accuracy: 0.6300, val/hateful_memes/binary_f1: 0.5824, val/hateful_memes/roc_auc: 0.7034, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 11s 884ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 7100/22000, train/total_loss: 0.0062, train/total_loss/avg: 0.1455, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1455, max mem: 11430.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 785ms, time_since_start: 03h 36m 42s 945ms, eta: 07h 16m 31s 985ms\n",
      "INFO:mmf.train:progress: 7200/22000, train/total_loss: 0.0062, train/total_loss/avg: 0.1438, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1438, max mem: 11430.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 277ms, time_since_start: 03h 39m 39s 223ms, eta: 07h 14m 49s 051ms\n",
      "INFO:mmf.train:progress: 7300/22000, train/total_loss: 0.0062, train/total_loss/avg: 0.1419, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1419, max mem: 11430.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 345ms, time_since_start: 03h 42m 34s 568ms, eta: 07h 09m 35s 744ms\n",
      "INFO:mmf.train:progress: 7400/22000, train/total_loss: 0.0068, train/total_loss/avg: 0.1416, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.1416, max mem: 11430.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 382ms, time_since_start: 03h 45m 29s 951ms, eta: 07h 06m 45s 864ms\n",
      "INFO:mmf.train:progress: 7500/22000, train/total_loss: 0.0068, train/total_loss/avg: 0.1398, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.1398, max mem: 11430.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 159ms, time_since_start: 03h 48m 26s 110ms, eta: 07h 05m 43s 148ms\n",
      "INFO:mmf.train:progress: 7600/22000, train/total_loss: 0.0062, train/total_loss/avg: 0.1379, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1379, max mem: 11430.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 660ms, time_since_start: 03h 51m 21s 771ms, eta: 07h 01m 35s 141ms\n",
      "INFO:mmf.train:progress: 7700/22000, train/total_loss: 0.0057, train/total_loss/avg: 0.1361, train/hateful_memes/cross_entropy: 0.0057, train/hateful_memes/cross_entropy/avg: 0.1361, max mem: 11430.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 829ms, time_since_start: 03h 54m 17s 601ms, eta: 06h 59m 03s 683ms\n",
      "INFO:mmf.train:progress: 7800/22000, train/total_loss: 0.0023, train/total_loss/avg: 0.1344, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1344, max mem: 11430.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 539ms, time_since_start: 03h 57m 14s 141ms, eta: 06h 57m 48s 648ms\n",
      "INFO:mmf.train:progress: 7900/22000, train/total_loss: 0.0023, train/total_loss/avg: 0.1330, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1330, max mem: 11430.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 55s 550ms, time_since_start: 04h 09s 691ms, eta: 06h 52m 32s 635ms\n",
      "INFO:mmf.train:progress: 8000/22000, train/total_loss: 0.0023, train/total_loss/avg: 0.1314, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1314, max mem: 11430.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00004, ups: 0.57, time: 02m 56s 231ms, time_since_start: 04h 03m 05s 923ms, eta: 06h 51m 12s 431ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 8000/22000, val/total_loss: 2.4925, val/hateful_memes/cross_entropy: 2.4925, val/hateful_memes/accuracy: 0.6120, val/hateful_memes/binary_f1: 0.5026, val/hateful_memes/roc_auc: 0.6970, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 12s 141ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 8100/22000, train/total_loss: 0.0023, train/total_loss/avg: 0.1299, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1299, max mem: 11430.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 887ms, time_since_start: 04h 06m 24s 574ms, eta: 06h 47m 28s 328ms\n",
      "INFO:mmf.train:progress: 8200/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1284, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1284, max mem: 11430.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 118ms, time_since_start: 04h 09m 19s 693ms, eta: 06h 42m 46s 418ms\n",
      "INFO:mmf.train:progress: 8300/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1268, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1268, max mem: 11430.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 423ms, time_since_start: 04h 12m 15s 116ms, eta: 06h 40m 32s 958ms\n",
      "INFO:mmf.train:progress: 8400/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1253, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1253, max mem: 11430.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 359ms, time_since_start: 04h 15m 09s 475ms, eta: 06h 35m 12s 912ms\n",
      "INFO:mmf.train:progress: 8500/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1239, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1239, max mem: 11430.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 610ms, time_since_start: 04h 18m 04s 086ms, eta: 06h 32m 52s 458ms\n",
      "INFO:mmf.train:progress: 8600/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1225, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1225, max mem: 11430.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 088ms, time_since_start: 04h 20m 59s 175ms, eta: 06h 31m 01s 899ms\n",
      "INFO:mmf.train:progress: 8700/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1211, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1211, max mem: 11430.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 821ms, time_since_start: 04h 23m 53s 996ms, eta: 06h 27m 31s 201ms\n",
      "INFO:mmf.train:progress: 8800/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1198, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1198, max mem: 11430.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 802ms, time_since_start: 04h 26m 49s 799ms, eta: 06h 26m 45s 917ms\n",
      "INFO:mmf.train:progress: 8900/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1186, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1186, max mem: 11430.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 693ms, time_since_start: 04h 29m 44s 492ms, eta: 06h 21m 24s 890ms\n",
      "INFO:mmf.train:progress: 9000/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1173, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1173, max mem: 11430.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 419ms, time_since_start: 04h 32m 39s 912ms, eta: 06h 20m 04s 481ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 9000/22000, val/total_loss: 2.0374, val/hateful_memes/cross_entropy: 2.0374, val/hateful_memes/accuracy: 0.6260, val/hateful_memes/binary_f1: 0.5681, val/hateful_memes/roc_auc: 0.7082, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 12s 205ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 9100/22000, train/total_loss: 0.0018, train/total_loss/avg: 0.1160, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1160, max mem: 11430.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 343ms, time_since_start: 04h 35m 59s 228ms, eta: 06h 19m 08s 291ms\n",
      "INFO:mmf.train:progress: 9200/22000, train/total_loss: 0.0018, train/total_loss/avg: 0.1148, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1148, max mem: 11430.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 436ms, time_since_start: 04h 38m 54s 664ms, eta: 06h 14m 15s 888ms\n",
      "INFO:mmf.train:progress: 9300/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1138, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1138, max mem: 11430.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 337ms, time_since_start: 04h 41m 50s 002ms, eta: 06h 11m 07s 837ms\n",
      "INFO:mmf.train:progress: 9400/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1126, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1126, max mem: 11430.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 705ms, time_since_start: 04h 44m 46s 707ms, eta: 06h 11m 04s 865ms\n",
      "INFO:mmf.train:progress: 9500/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1115, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1115, max mem: 11430.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 712ms, time_since_start: 04h 47m 42s 419ms, eta: 06h 06m 04s 062ms\n",
      "INFO:mmf.train:progress: 9600/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1103, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1103, max mem: 11430.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 472ms, time_since_start: 04h 50m 38s 892ms, eta: 06h 04m 42s 632ms\n",
      "INFO:mmf.train:progress: 9700/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.1094, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.1094, max mem: 11430.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 515ms, time_since_start: 04h 53m 34s 408ms, eta: 05h 59m 48s 391ms\n",
      "INFO:mmf.train:progress: 9800/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.1083, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.1083, max mem: 11430.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 642ms, time_since_start: 04h 56m 30s 050ms, eta: 05h 57m 08s 378ms\n",
      "INFO:mmf.train:progress: 9900/22000, train/total_loss: 0.0021, train/total_loss/avg: 0.1072, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1072, max mem: 11430.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 014ms, time_since_start: 04h 59m 26s 064ms, eta: 05h 54m 57s 710ms\n",
      "INFO:mmf.train:progress: 10000/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1062, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1062, max mem: 11430.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 263ms, time_since_start: 05h 02m 21s 328ms, eta: 05h 50m 31s 617ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 10000/22000, val/total_loss: 2.3947, val/hateful_memes/cross_entropy: 2.3947, val/hateful_memes/accuracy: 0.6340, val/hateful_memes/binary_f1: 0.5367, val/hateful_memes/roc_auc: 0.6596, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 12s 209ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 10100/22000, train/total_loss: 0.0018, train/total_loss/avg: 0.1051, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1051, max mem: 11430.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 087ms, time_since_start: 05h 05m 40s 581ms, eta: 05h 49m 14s 358ms\n",
      "INFO:mmf.train:progress: 10200/22000, train/total_loss: 0.0018, train/total_loss/avg: 0.1042, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1042, max mem: 11430.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 070ms, time_since_start: 05h 08m 36s 652ms, eta: 05h 46m 16s 371ms\n",
      "INFO:mmf.train:progress: 10300/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1034, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1034, max mem: 11430.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 825ms, time_since_start: 05h 11m 32s 478ms, eta: 05h 42m 51s 584ms\n",
      "INFO:mmf.train:progress: 10400/22000, train/total_loss: 0.0019, train/total_loss/avg: 0.1024, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1024, max mem: 11430.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 0.56, time: 02m 57s 002ms, time_since_start: 05h 14m 29s 481ms, eta: 05h 42m 12s 347ms\n",
      "INFO:mmf.train:progress: 10500/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.1015, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.1015, max mem: 11430.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 275ms, time_since_start: 05h 17m 24s 757ms, eta: 05h 35m 56s 737ms\n",
      "INFO:mmf.train:progress: 10700/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.1001, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.1001, max mem: 11430.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 974ms, time_since_start: 05h 23m 15s 901ms, eta: 05h 31m 25s 107ms\n",
      "INFO:mmf.train:progress: 10800/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.0993, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.0993, max mem: 11430.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 752ms, time_since_start: 05h 26m 11s 654ms, eta: 05h 28m 04s 333ms\n",
      "INFO:mmf.train:progress: 10900/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.0984, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.0984, max mem: 11430.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 550ms, time_since_start: 05h 29m 07s 204ms, eta: 05h 24m 46s 142ms\n",
      "INFO:mmf.train:progress: 11000/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.0975, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.0975, max mem: 11430.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 414ms, time_since_start: 05h 32m 03s 619ms, eta: 05h 23m 25s 620ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 11000/22000, val/total_loss: 2.4892, val/hateful_memes/cross_entropy: 2.4892, val/hateful_memes/accuracy: 0.6200, val/hateful_memes/binary_f1: 0.4920, val/hateful_memes/roc_auc: 0.6877, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 11s 762ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 11100/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.0967, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.0967, max mem: 11430.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 743ms, time_since_start: 05h 35m 21s 887ms, eta: 05h 19m 15s 996ms\n",
      "INFO:mmf.train:progress: 11200/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.0960, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.0960, max mem: 11430.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 154ms, time_since_start: 05h 38m 18s 042ms, eta: 05h 17m 04s 649ms\n",
      "INFO:mmf.train:progress: 11300/22000, train/total_loss: 0.0024, train/total_loss/avg: 0.0951, train/hateful_memes/cross_entropy: 0.0024, train/hateful_memes/cross_entropy/avg: 0.0951, max mem: 11430.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 976ms, time_since_start: 05h 41m 13s 018ms, eta: 05h 12m 02s 501ms\n",
      "INFO:mmf.train:progress: 11400/22000, train/total_loss: 0.0014, train/total_loss/avg: 0.0943, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.0943, max mem: 11430.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 123ms, time_since_start: 05h 44m 08s 142ms, eta: 05h 09m 23s 114ms\n",
      "INFO:mmf.train:progress: 11500/22000, train/total_loss: 0.0010, train/total_loss/avg: 0.0935, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0935, max mem: 11430.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 039ms, time_since_start: 05h 47m 04s 182ms, eta: 05h 08m 04s 198ms\n",
      "INFO:mmf.train:progress: 11600/22000, train/total_loss: 0.0010, train/total_loss/avg: 0.0929, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0929, max mem: 11430.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 236ms, time_since_start: 05h 49m 59s 418ms, eta: 05h 03m 44s 575ms\n",
      "INFO:mmf.train:progress: 11700/22000, train/total_loss: 0.0010, train/total_loss/avg: 0.0922, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0922, max mem: 11430.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 54s 426ms, time_since_start: 05h 52m 53s 845ms, eta: 04h 59m 25s 972ms\n",
      "INFO:mmf.train:progress: 11800/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0914, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0914, max mem: 11430.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 803ms, time_since_start: 05h 55m 49s 649ms, eta: 04h 58m 51s 951ms\n",
      "INFO:mmf.train:progress: 11900/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0909, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0909, max mem: 11430.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 254ms, time_since_start: 05h 58m 44s 903ms, eta: 04h 55m 675ms\n",
      "INFO:mmf.train:progress: 12000/22000, train/total_loss: 0.0026, train/total_loss/avg: 0.0901, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.0901, max mem: 11430.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 091ms, time_since_start: 06h 01m 40s 994ms, eta: 04h 53m 29s 135ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 12000/22000, val/total_loss: 2.2916, val/hateful_memes/cross_entropy: 2.2916, val/hateful_memes/accuracy: 0.6120, val/hateful_memes/binary_f1: 0.4921, val/hateful_memes/roc_auc: 0.6908, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 11s 666ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 12100/22000, train/total_loss: 0.0029, train/total_loss/avg: 0.0894, train/hateful_memes/cross_entropy: 0.0029, train/hateful_memes/cross_entropy/avg: 0.0894, max mem: 11430.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 289ms, time_since_start: 06h 04m 58s 811ms, eta: 04h 49m 13s 643ms\n",
      "INFO:mmf.train:progress: 12200/22000, train/total_loss: 0.0029, train/total_loss/avg: 0.0894, train/hateful_memes/cross_entropy: 0.0029, train/hateful_memes/cross_entropy/avg: 0.0894, max mem: 11430.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 180ms, time_since_start: 06h 07m 53s 991ms, eta: 04h 46m 07s 675ms\n",
      "INFO:mmf.train:progress: 12300/22000, train/total_loss: 0.0026, train/total_loss/avg: 0.0886, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.0886, max mem: 11430.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 592ms, time_since_start: 06h 10m 49s 583ms, eta: 04h 43m 52s 443ms\n",
      "INFO:mmf.train:progress: 12400/22000, train/total_loss: 0.0026, train/total_loss/avg: 0.0879, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.0879, max mem: 11430.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 969ms, time_since_start: 06h 13m 45s 553ms, eta: 04h 41m 33s 089ms\n",
      "INFO:mmf.train:progress: 12500/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0872, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0872, max mem: 11430.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 341ms, time_since_start: 06h 16m 40s 894ms, eta: 04h 37m 37s 453ms\n",
      "INFO:mmf.train:progress: 12600/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0865, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0865, max mem: 11430.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 56s 389ms, time_since_start: 06h 19m 37s 284ms, eta: 04h 36m 20s 627ms\n",
      "INFO:mmf.train:progress: 12700/22000, train/total_loss: 0.0025, train/total_loss/avg: 0.0862, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0862, max mem: 11430.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 54s 962ms, time_since_start: 06h 22m 32s 247ms, eta: 04h 31m 11s 519ms\n",
      "INFO:mmf.train:progress: 12800/22000, train/total_loss: 0.0013, train/total_loss/avg: 0.0855, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0855, max mem: 11430.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 585ms, time_since_start: 06h 25m 27s 832ms, eta: 04h 29m 13s 893ms\n",
      "INFO:mmf.train:progress: 12900/22000, train/total_loss: 0.0013, train/total_loss/avg: 0.0848, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0848, max mem: 11430.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 332ms, time_since_start: 06h 28m 23s 165ms, eta: 04h 25m 55s 268ms\n",
      "INFO:mmf.train:progress: 13000/22000, train/total_loss: 0.0013, train/total_loss/avg: 0.0842, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0842, max mem: 11430.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 179ms, time_since_start: 06h 31m 18s 345ms, eta: 04h 22m 46s 146ms\n",
      "INFO:mmf.train:Checkpoint time. Saving a checkpoint.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "\n",
      "INFO:mmf.train:Evaluation time. Running on full validation set...\n",
      "INFO:mmf.train:progress: 13000/22000, val/total_loss: 2.3802, val/hateful_memes/cross_entropy: 2.3802, val/hateful_memes/accuracy: 0.6360, val/hateful_memes/binary_f1: 0.5404, val/hateful_memes/roc_auc: 0.7054, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 12s 089ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.736096\n",
      "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "INFO:mmf.train:progress: 13100/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0836, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0836, max mem: 11430.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 56s 477ms, time_since_start: 06h 34m 37s 828ms, eta: 04h 21m 46s 509ms\n",
      "INFO:mmf.train:progress: 13200/22000, train/total_loss: 0.0011, train/total_loss/avg: 0.0830, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0830, max mem: 11430.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 284ms, time_since_start: 06h 37m 33s 113ms, eta: 04h 17m 05s 037ms\n",
      "INFO:mmf.train:progress: 13300/22000, train/total_loss: 0.0012, train/total_loss/avg: 0.0827, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0827, max mem: 11430.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 54s 035ms, time_since_start: 06h 40m 27s 148ms, eta: 04h 12m 21s 073ms\n",
      "INFO:mmf.train:progress: 13400/22000, train/total_loss: 0.0013, train/total_loss/avg: 0.0821, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0821, max mem: 11430.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 56s 635ms, time_since_start: 06h 43m 23s 784ms, eta: 04h 13m 10s 670ms\n",
      "INFO:mmf.train:progress: 13500/22000, train/total_loss: 0.0025, train/total_loss/avg: 0.0816, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0816, max mem: 11430.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 54s 877ms, time_since_start: 06h 46m 18s 661ms, eta: 04h 07m 44s 559ms\n",
      "INFO:mmf.train:progress: 13600/22000, train/total_loss: 0.0025, train/total_loss/avg: 0.0810, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0810, max mem: 11430.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 805ms, time_since_start: 06h 49m 14s 466ms, eta: 04h 06m 07s 633ms\n",
      "Process Process-260:\n",
      "Process Process-258:\n",
      "Process Process-259:\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0f7cd0ccb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "Process Process-257:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#Запуск обучения\n",
    "\n",
    "!mmf_run \\\n",
    "config=mmf/projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
    "model=visual_bert \\\n",
    "dataset=hateful_memes \\\n",
    "training.batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amcSnisyRrLa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1665671647207,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "7MPguh3-xBKE",
    "outputId": "7949a172-3059-423d-fe1e-07be7186e283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best.ckpt    current_14-18.ckpt  logs\t train.log\n",
      "config.yaml  current.ckpt\t models\n"
     ]
    }
   ],
   "source": [
    "!ls save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46419,
     "status": "ok",
     "timestamp": 1665671751751,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "MWXe11IMRrQU",
    "outputId": "1ce7a6ac-7511-44ab-a8d6-d4c261b1984c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_override=None, local_rank=None, opts=['config=./save/config.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=./save/best.ckpt', 'checkpoint.resume_pretrained=False'])\n",
      "/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "Overriding option config to ./save/config.yaml\n",
      "Overriding option model to visual_bert\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to val\n",
      "Overriding option checkpoint.resume_file to ./save/best.ckpt\n",
      "Overriding option checkpoint.resume_pretrained to False\n",
      "Using seed 48053078\n",
      "Logging to: ./save/logs/train_2022-10-13T14:35:18.log\n",
      "INFO:mmf.train:Loading datasets\n",
      "INFO:mmf.train:CUDA Device 0 is: Tesla T4\n",
      "INFO:mmf.train:Torch version is: 1.5.0\n",
      "INFO:mmf.train:Loading checkpoint\n",
      "INFO:mmf.train:Checkpoint loaded\n",
      "INFO:mmf.train:===== Model =====\n",
      "INFO:mmf.train:VisualBERT(\n",
      "  (model): VisualBERTForClassification(\n",
      "    (bert): VisualBERTBase(\n",
      "      (embeddings): BertVisioLinguisticEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (token_type_embeddings_visual): Embedding(2, 768)\n",
      "        (position_embeddings_visual): Embedding(512, 768)\n",
      "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Sequential(\n",
      "      (0): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (losses): Losses()\n",
      ")\n",
      "INFO:mmf.train:Total Parameters: 112044290. Trained Parameters: 112044290\n",
      "INFO:mmf.train:Starting inference on val set\n",
      "16it [00:11,  1.39it/s]\n",
      "INFO:mmf.train:progress: 2000/22000, val/total_loss: 1.0321, val/hateful_memes/cross_entropy: 1.0321, val/hateful_memes/accuracy: 0.6440, val/hateful_memes/binary_f1: 0.5266, val/hateful_memes/roc_auc: 0.7361\n"
     ]
    }
   ],
   "source": [
    "#Валидация\n",
    "\n",
    "!mmf_run \\\n",
    "config=./save/config.yaml \\\n",
    "model=visual_bert \\\n",
    "dataset=hateful_memes \\\n",
    "run_type=val \\\n",
    "checkpoint.resume_file=./save/best.ckpt \\\n",
    "checkpoint.resume_pretrained=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1665671890417,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "617dy4vjRrUD",
    "outputId": "9e8a0fb4-3a95-49a0-fd10-b4252ee4501e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook-hateful-meme-dataset.zip  kaggle.json\tmmf  sample_data  save\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25978,
     "status": "ok",
     "timestamp": 1665672026949,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "E6CXIufVyM_1",
    "outputId": "23fc2939-e0e4-4ba8-81b3-8f79a10e72bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_override=None, local_rank=None, opts=['config=./save/config.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=./save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])\n",
      "/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "Overriding option config to ./save/config.yaml\n",
      "Overriding option model to visual_bert\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to val\n",
      "Overriding option checkpoint.resume_file to ./save/best.ckpt\n",
      "Overriding option checkpoint.resume_pretrained to False\n",
      "Overriding option evaluation.predict to true\n",
      "Using seed 48053078\n",
      "Logging to: ./save/logs/train_2022-10-13T14:40:06.log\n",
      "INFO:mmf.train:Loading datasets\n",
      "INFO:mmf.train:CUDA Device 0 is: Tesla T4\n",
      "INFO:mmf.train:Torch version is: 1.5.0\n",
      "INFO:mmf.train:Loading checkpoint\n",
      "INFO:mmf.train:Checkpoint loaded\n",
      "INFO:mmf.train:Starting val inference predictions\n",
      "INFO:mmf.train:Predicting for hateful_memes\n",
      "100% 16/16 [00:10<00:00,  1.48it/s]\n",
      "INFO:mmf.train:Wrote evalai predictions for hateful_memes to /content/save/hateful_memes_visual_bert_48053078/reports/hateful_memes_run_val_2022-10-13T14:40:25.csv\n",
      "INFO:mmf.train:Finished predicting\n"
     ]
    }
   ],
   "source": [
    "#Предсказание \n",
    "\n",
    "!mmf_predict \\\n",
    "config=./save/config.yaml \\\n",
    "model=visual_bert \\\n",
    "dataset=hateful_memes \\\n",
    "run_type=val \\\n",
    "checkpoint.resume_file=./save/best.ckpt \\\n",
    "checkpoint.resume_pretrained=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25172,
     "status": "ok",
     "timestamp": 1665672404359,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "URCGUNKTyNDq",
    "outputId": "e269ead5-ecec-46e8-ef70-ee0c3cdbf8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_override=None, local_rank=None, opts=['config=./save/config.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=./save/best.ckpt', 'checkpoint.resume_pretrained=False', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl', 'evaluation.predict=true'])\n",
      "/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
      "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
      "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "Overriding option config to ./save/config.yaml\n",
      "Overriding option model to visual_bert\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to val\n",
      "Overriding option checkpoint.resume_file to ./save/best.ckpt\n",
      "Overriding option checkpoint.resume_pretrained to False\n",
      "Overriding option evaluation.predict to true\n",
      "Using seed 48053078\n",
      "Logging to: ./save/logs/train_2022-10-13T14:46:24.log\n",
      "INFO:mmf.train:Loading datasets\n",
      "INFO:mmf.train:CUDA Device 0 is: Tesla T4\n",
      "INFO:mmf.train:Torch version is: 1.5.0\n",
      "INFO:mmf.train:Loading checkpoint\n",
      "INFO:mmf.train:Checkpoint loaded\n",
      "INFO:mmf.train:Starting val inference predictions\n",
      "INFO:mmf.train:Predicting for hateful_memes\n",
      "100% 16/16 [00:10<00:00,  1.55it/s]\n",
      "INFO:mmf.train:Wrote evalai predictions for hateful_memes to /content/save/hateful_memes_visual_bert_48053078/reports/hateful_memes_run_val_2022-10-13T14:46:42.csv\n",
      "INFO:mmf.train:Finished predicting\n"
     ]
    }
   ],
   "source": [
    "#!mmf_predict \\\n",
    "#config=./save/config.yaml \\\n",
    "#model=visual_bert \\\n",
    "#dataset=hateful_memes \\\n",
    "#run_type=val \\\n",
    "#checkpoint.resume_file=./save/best.ckpt \\\n",
    "#checkpoint.resume_pretrained=False \\\n",
    "#dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl \\\n",
    "#dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W889pnMvDdbY"
   },
   "outputs": [],
   "source": [
    "%cd save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1665673649584,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "lVNqBKt20QYG",
    "outputId": "78234c00-e0bd-4cd5-b2c4-ebc80b78a281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best.ckpt  config.yaml\thateful_memes_visual_bert_48053078  logs  train.log\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afzdxzBa0VB8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhP1zpf21dFc"
   },
   "outputs": [],
   "source": [
    "!tar -czpf save.tar *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665673838108,
     "user": {
      "displayName": "Шишкин Александр",
      "userId": "00721730077610513143"
     },
     "user_tz": -180
    },
    "id": "2CEAoeka1m5W",
    "outputId": "5ccb2aee-4674-4a61-cf1a-5d5f9775af7b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_84e80f29-abb8-4f68-b5e3-745382b9a2a0\", \"save.tar\", 1106687742)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download('save.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELKkVShL8gh3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exaqmxqJ8glG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
